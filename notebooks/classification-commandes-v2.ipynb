{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181720d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extraction d'entit√©s (slots) depuis les commandes utilisateur\n",
    "Plusieurs approches : Regex, SpaCy NER, et mod√®le seq2seq\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, Any, List, Optional\n",
    "import torch\n",
    "from transformers import (\n",
    "    CamembertTokenizerFast,  # Chang√© de CamembertTokenizer √† CamembertTokenizerFast\n",
    "    CamembertForTokenClassification,\n",
    "    pipeline\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "#Todo si erreur (windows ) : pip install \"numpy<2\"\n",
    "# pip install transformers[torch] sentencepiece protobuf\n",
    "# pip install --upgrade transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d49aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# APPROCHE 1: R√®gles et Regex (Simple et efficace pour cas simples)\n",
    "# ============================================================================\n",
    "\n",
    "class RuleBasedSlotExtractor:\n",
    "    \"\"\"Extracteur bas√© sur des r√®gles pour chaque intention\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'export_notation': [\n",
    "                (r'notation[s]?\\s+(?:num√©ro\\s+)?(\\d+)', 'notation_id'),\n",
    "                (r'n¬∞\\s*(\\d+)', 'notation_id'),\n",
    "                (r'la\\s+(\\d+)', 'notation_id'),\n",
    "                (r'(?:^|\\s)(\\d+)(?:$|\\s)', 'notation_id'),  # nombre seul\n",
    "            ],\n",
    "            'creer_notation': [\n",
    "                (r'notation\\s+\"([^\"]+)\"', 'notation_nom'),\n",
    "                (r'notation\\s+(.+?)(?:\\s+pour|\\s+sur|$)', 'notation_nom'),\n",
    "            ],\n",
    "            'creer_essai': [\n",
    "                (r'essai\\s+\"([^\"]+)\"', 'essai_nom'),\n",
    "                (r'essai\\s+(.+?)(?:\\s+pour|\\s+sur|$)', 'essai_nom'),\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def extract(self, text: str, intent: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extrait les slots pour une intention donn√©e\"\"\"\n",
    "        slots = {}\n",
    "        \n",
    "        if intent not in self.patterns:\n",
    "            return slots\n",
    "        \n",
    "        for pattern, slot_name in self.patterns[intent]:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                value = match.group(1)\n",
    "                slots[slot_name] = value.strip()\n",
    "                break  # Prend le premier match\n",
    "        \n",
    "        return slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025f799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a0b5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SC√âNARIO 1: Entra√Ænement d'un nouveau mod√®le\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/tmp/ipykernel_7590/3170723008.py:170: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Pr√©paration des donn√©es d'entra√Ænement...\n",
      "   Nombre d'exemples: 38\n",
      "üöÄ D√©but de l'entra√Ænement...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 09:10, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.664800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.641000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.533400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.417800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.330500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.270200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.977800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.512900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.382900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.319800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.316500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.287800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.284800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.282300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.282400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä R√©sultats de l'entra√Ænement:\n",
      "   Loss finale: 0.6909\n",
      "üíæ Sauvegarde du mod√®le dans ./models/ner-notation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entra√Ænement termin√© !\n",
      "\n",
      "============================================================\n",
      "TESTS D'EXTRACTION\n",
      "============================================================\n",
      "\n",
      "üìù Phrase: je veux exporter la notation 34\n",
      "üéØ Slots: {}\n",
      "\n",
      "üìù Phrase: export notation 789\n",
      "üéØ Slots: {}\n",
      "\n",
      "üìù Phrase: exporter l'essai 555\n",
      "üéØ Slots: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Phrase: cr√©er une nouvelle notation test\n",
      "üéØ Slots: {}\n",
      "\n",
      "============================================================\n",
      "SC√âNARIO 2: Charger un mod√®le existant\n",
      "============================================================\n",
      "üì• Chargement du mod√®le depuis ./models/ner-notation\n",
      "\n",
      "üìù Phrase: je veux exporter la notation 99\n",
      "üéØ Slots: {}\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    CamembertTokenizerFast, \n",
    "    CamembertForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict, Optional\n",
    "import torch\n",
    "\n",
    "class NERSlotExtractor:\n",
    "    \"\"\"\n",
    "    Extraction de slots avec un mod√®le NER (Named Entity Recognition)\n",
    "    Utilise BIO tagging: B-notation_id, I-notation_id, O\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: Optional[str] = None):\n",
    "        # Labels BIO pour chaque type d'entit√©\n",
    "        self.label_list = [\n",
    "            'O',\n",
    "            'B-notation_id',\n",
    "            'B-essai_id',\n",
    "            'B-nom',\n",
    "            'I-nom',\n",
    "        ]\n",
    "        \n",
    "        self.label2id = {label: i for i, label in enumerate(self.label_list)}\n",
    "        self.id2label = {i: label for i, label in enumerate(self.label_list)}\n",
    "        \n",
    "        # Charger le tokenizer\n",
    "        if model_path:\n",
    "            self.tokenizer = CamembertTokenizerFast.from_pretrained(model_path)\n",
    "            self.model = CamembertForTokenClassification.from_pretrained(model_path)\n",
    "        else:\n",
    "            self.tokenizer = CamembertTokenizerFast.from_pretrained('camembert-base')\n",
    "            self.model = CamembertForTokenClassification.from_pretrained(\n",
    "                'camembert-base',\n",
    "                num_labels=len(self.label_list),\n",
    "                id2label=self.id2label,\n",
    "                label2id=self.label2id\n",
    "            )\n",
    "        \n",
    "        # Pipeline NER (sera cr√©√© apr√®s l'entra√Ænement)\n",
    "        self.ner_pipeline = None\n",
    "    \n",
    "\n",
    "    def create_training_data(self):\n",
    "        \"\"\"Cr√©e des donn√©es d'entra√Ænement annot√©es au format BIO - VERSION AUGMENT√âE\"\"\"\n",
    "        examples = [\n",
    "            # Variations pour notation_id\n",
    "            (\"export de la notation 123\", [(22, 25, 'notation_id')]),\n",
    "            (\"exporter notation 456\", [(18, 21, 'notation_id')]),\n",
    "            (\"je veux exporter la notation 789\", [(29, 32, 'notation_id')]),\n",
    "            (\"je veux exporter la notation num√©ro 789\", [(37, 40, 'notation_id')]),\n",
    "            (\"export notation 12\", [(16, 18, 'notation_id')]),\n",
    "            (\"exporte la notation 999\", [(19, 22, 'notation_id')]),\n",
    "            (\"notation 555 √† exporter\", [(9, 12, 'notation_id')]),\n",
    "            (\"exporter la notation 1\", [(21, 22, 'notation_id')]),\n",
    "            (\"je souhaite exporter la notation 234\", [(33, 36, 'notation_id')]),\n",
    "            (\"peux-tu exporter la notation 567\", [(29, 32, 'notation_id')]),\n",
    "            (\"export la notation 890\", [(19, 22, 'notation_id')]),\n",
    "            (\"notation 111\", [(9, 12, 'notation_id')]),\n",
    "            (\"la notation 222\", [(12, 15, 'notation_id')]),\n",
    "            (\"voir la notation 333\", [(17, 20, 'notation_id')]),\n",
    "            (\"afficher notation 444\", [(18, 21, 'notation_id')]),\n",
    "            (\"r√©cup√©rer notation 555\", [(19, 22, 'notation_id')]),\n",
    "            (\"t√©l√©charger notation 666\", [(21, 24, 'notation_id')]),\n",
    "            (\"exporte notation 777\", [(17, 20, 'notation_id')]),\n",
    "            (\"extraire notation 888\", [(18, 21, 'notation_id')]),\n",
    "            (\"sortir notation 999\", [(16, 19, 'notation_id')]),\n",
    "            \n",
    "            # Variations pour essai_id\n",
    "            (\"essai 777\", [(6, 9, 'essai_id')]),\n",
    "            (\"export de l'essai 888\", [(18, 21, 'essai_id')]),\n",
    "            (\"exporter l'essai 999\", [(17, 20, 'essai_id')]),\n",
    "            (\"je veux l'essai 111\", [(16, 19, 'essai_id')]),\n",
    "            (\"voir essai 222\", [(11, 14, 'essai_id')]),\n",
    "            (\"essai num√©ro 333\", [(13, 16, 'essai_id')]),\n",
    "            (\"r√©cup√©rer essai 444\", [(16, 19, 'essai_id')]),\n",
    "            (\"l'essai 555\", [(8, 11, 'essai_id')]),\n",
    "            \n",
    "            # Exemples sans entit√©s (important !)\n",
    "            (\"cr√©er une notation\", []),\n",
    "            (\"nouvelle notation\", []),\n",
    "            (\"je veux cr√©er\", []),\n",
    "            (\"exporter\", []),\n",
    "            (\"afficher tout\", []),\n",
    "            (\"liste des notations\", []),\n",
    "            (\"voir les essais\", []),\n",
    "            (\"bonjour\", []),\n",
    "            (\"merci\", []),\n",
    "            (\"aide\", []),\n",
    "        ]\n",
    "        \n",
    "        tokenized_examples = []\n",
    "        \n",
    "        for text, entities in examples:\n",
    "            encoding = self.tokenizer(\n",
    "                text, \n",
    "                return_offsets_mapping=True, \n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            tokens = self.tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n",
    "            offsets = encoding['offset_mapping']\n",
    "            \n",
    "            labels = [self.label2id['O']] * len(tokens)\n",
    "            \n",
    "            for start, end, entity_type in entities:\n",
    "                for idx, (token_start, token_end) in enumerate(offsets):\n",
    "                    if token_start is None:\n",
    "                        labels[idx] = -100\n",
    "                        continue\n",
    "                    \n",
    "                    if token_start >= start and token_end <= end:\n",
    "                        if token_start == start:\n",
    "                            labels[idx] = self.label2id[f'B-{entity_type}']\n",
    "                        else:\n",
    "                            labels[idx] = self.label2id.get(f'I-{entity_type}', \n",
    "                                                            self.label2id[f'B-{entity_type}'])\n",
    "            \n",
    "            tokenized_examples.append({\n",
    "                'input_ids': encoding['input_ids'],\n",
    "                'attention_mask': encoding['attention_mask'],\n",
    "                'labels': labels\n",
    "            })\n",
    "        \n",
    "        return tokenized_examples\n",
    "    \n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        output_dir: str = \"./models/ner-notation\",\n",
    "        num_epochs: int = 50,  # Beaucoup plus d'√©poques\n",
    "        batch_size: int = 4,   # Batch plus petit\n",
    "        learning_rate: float = 2e-5,  # Learning rate plus petit\n",
    "        save_model: bool = True\n",
    "    ):\n",
    "        \"\"\"Entra√Æne le mod√®le NER sur les donn√©es annot√©es\"\"\"\n",
    "        print(\"üìö Pr√©paration des donn√©es d'entra√Ænement...\")\n",
    "        training_data = self.create_training_data()\n",
    "        \n",
    "        print(f\"   Nombre d'exemples: {len(training_data)}\")\n",
    "        \n",
    "        dataset = Dataset.from_list(training_data)\n",
    "        \n",
    "        data_collator = DataCollatorForTokenClassification(\n",
    "            tokenizer=self.tokenizer,\n",
    "            padding=True\n",
    "        )\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=f'{output_dir}/logs',\n",
    "            logging_steps=5,\n",
    "            save_strategy=\"epoch\",\n",
    "            eval_strategy=\"no\",\n",
    "            warmup_steps=100,  # Warmup pour stabiliser l'entra√Ænement\n",
    "            save_total_limit=2,  # Garde seulement les 2 derniers checkpoints\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset,\n",
    "            tokenizer=self.tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        \n",
    "        print(\"üöÄ D√©but de l'entra√Ænement...\")\n",
    "        train_result = trainer.train()\n",
    "        \n",
    "        print(f\"\\nüìä R√©sultats de l'entra√Ænement:\")\n",
    "        print(f\"   Loss finale: {train_result.training_loss:.4f}\")\n",
    "        \n",
    "        if save_model:\n",
    "            print(f\"üíæ Sauvegarde du mod√®le dans {output_dir}\")\n",
    "            self.model.save_pretrained(output_dir)\n",
    "            self.tokenizer.save_pretrained(output_dir)\n",
    "        \n",
    "        self._create_pipeline()\n",
    "        \n",
    "        print(\"‚úÖ Entra√Ænement termin√© !\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _create_pipeline(self):\n",
    "        \"\"\"Cr√©e le pipeline NER pour l'inf√©rence\"\"\"\n",
    "        self.ner_pipeline = pipeline(\n",
    "            \"ner\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            aggregation_strategy=\"simple\",\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "    \n",
    "    def extract_slots(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Extrait les slots d'une phrase\n",
    "        \n",
    "        Args:\n",
    "            text: La phrase √† analyser (ex: \"je veux exporter la notation 34\")\n",
    "        \n",
    "        Returns:\n",
    "            Dictionnaire des slots (ex: {'notation_id': '34'})\n",
    "        \"\"\"\n",
    "        if self.ner_pipeline is None:\n",
    "            self._create_pipeline()\n",
    "        \n",
    "        # Pr√©diction NER\n",
    "        entities = self.ner_pipeline(text)\n",
    "        \n",
    "        # Conversion en dictionnaire de slots\n",
    "        slots = {}\n",
    "        for entity in entities:\n",
    "            # Nettoie le label (enl√®ve B- ou I- si pr√©sent)\n",
    "            slot_name = entity['entity_group'].replace('B-', '').replace('I-', '')\n",
    "            slot_value = entity['word'].strip()\n",
    "            \n",
    "            # Si le slot existe d√©j√†, concat√®ne (pour g√©rer les multi-tokens)\n",
    "            if slot_name in slots:\n",
    "                slots[slot_name] += ' ' + slot_value\n",
    "            else:\n",
    "                slots[slot_name] = slot_value\n",
    "        \n",
    "        return slots\n",
    "    \n",
    "    @classmethod\n",
    "    def load_trained_model(cls, model_path: str):\n",
    "        \"\"\"\n",
    "        Charge un mod√®le d√©j√† entra√Æn√©\n",
    "        \n",
    "        Args:\n",
    "            model_path: Chemin vers le mod√®le sauvegard√©\n",
    "        \n",
    "        Returns:\n",
    "            Instance de NERSlotExtractor avec le mod√®le charg√©\n",
    "        \"\"\"\n",
    "        print(f\"üì• Chargement du mod√®le depuis {model_path}\")\n",
    "        return cls(model_path=model_path)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UTILISATION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sc√©nario 1: Entra√Æner un nouveau mod√®le\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SC√âNARIO 1: Entra√Ænement d'un nouveau mod√®le\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    extractor = NERSlotExtractor()\n",
    "    extractor.train(\n",
    "        output_dir=\"./models/ner-notation\",\n",
    "        num_epochs=20,  # Plus d'√©poques pour un petit dataset\n",
    "        batch_size=4,\n",
    "        learning_rate=2e-5\n",
    "    )\n",
    "    \n",
    "    # Tester l'extraction\n",
    "    test_phrases = [\n",
    "        \"je veux exporter la notation 34\",\n",
    "        \"export notation 789\",\n",
    "        \"exporter l'essai 555\",\n",
    "        \"cr√©er une nouvelle notation test\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TESTS D'EXTRACTION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for phrase in test_phrases:\n",
    "        slots = extractor.extract_slots(phrase)\n",
    "        print(f\"\\nüìù Phrase: {phrase}\")\n",
    "        print(f\"üéØ Slots: {slots}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SC√âNARIO 2: Charger un mod√®le existant\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Charger le mod√®le entra√Æn√©\n",
    "    extractor_loaded = NERSlotExtractor.load_trained_model(\"./models/ner-notation\")\n",
    "    \n",
    "    # Tester\n",
    "    result = extractor_loaded.extract_slots(\"je veux exporter la notation 99\")\n",
    "    print(f\"\\nüìù Phrase: je veux exporter la notation 99\")\n",
    "    print(f\"üéØ Slots: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cea6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'export de la notation 123',\n",
       "  'tokens': ['<s>', '‚ñÅexport', '‚ñÅde', '‚ñÅla', '‚ñÅnotation', '‚ñÅ123', '</s>'],\n",
       "  'labels': ['O', 'O', 'O', 'O', 'O', 'B-notation_id', 'O'],\n",
       "  'input_ids': [5, 13056, 8, 13, 18231, 18634, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'exporter notation 456',\n",
       "  'tokens': ['<s>', '‚ñÅexport', 'er', '‚ñÅnotation', '‚ñÅ4', '56', '</s>'],\n",
       "  'labels': ['O', 'O', 'O', 'O', 'B-notation_id', 'I-notation_id', 'O'],\n",
       "  'input_ids': [5, 13056, 108, 18231, 181, 4876, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'je veux exporter la notation num√©ro 789',\n",
       "  'tokens': ['<s>',\n",
       "   '‚ñÅje',\n",
       "   '‚ñÅveux',\n",
       "   '‚ñÅexport',\n",
       "   'er',\n",
       "   '‚ñÅla',\n",
       "   '‚ñÅnotation',\n",
       "   '‚ñÅnum√©ro',\n",
       "   '‚ñÅ7',\n",
       "   '89',\n",
       "   '</s>'],\n",
       "  'labels': ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-notation_id',\n",
       "   'O'],\n",
       "  'input_ids': [5, 50, 920, 13056, 108, 13, 18231, 1124, 333, 4283, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'export notation 12',\n",
       "  'tokens': ['<s>', '‚ñÅexport', '‚ñÅnotation', '‚ñÅ12', '</s>'],\n",
       "  'labels': ['O', 'O', 'O', 'B-notation_id', 'O'],\n",
       "  'input_ids': [5, 13056, 18231, 409, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1]},\n",
       " {'text': 'cr√©er une notation',\n",
       "  'tokens': ['<s>', '‚ñÅcr√©er', '‚ñÅune', '‚ñÅnotation', '</s>'],\n",
       "  'labels': ['O', 'O', 'O', 'O', 'O'],\n",
       "  'input_ids': [5, 739, 28, 18231, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1]},\n",
       " {'text': 'cr√©er un essai test',\n",
       "  'tokens': ['<s>', '‚ñÅcr√©er', '‚ñÅun', '‚ñÅessai', '‚ñÅtest', '</s>'],\n",
       "  'labels': ['O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  'input_ids': [5, 739, 23, 5778, 2006, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1]},\n",
       " {'text': 'nouvelle notation pour analyse',\n",
       "  'tokens': ['<s>', '‚ñÅnouvelle', '‚ñÅnotation', '‚ñÅpour', '‚ñÅanalyse', '</s>'],\n",
       "  'labels': ['O', 'O', 'O', 'O', 'I-nom', 'O'],\n",
       "  'input_ids': [5, 304, 18231, 24, 2646, 6],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = NERSlotExtractor()\n",
    "extractor.create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c3d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# ============================================================================\n",
    "# APPROCHE 3: Template avec LLM (Plus puissant mais plus co√ªteux)\n",
    "# ============================================================================\n",
    "\n",
    "class MistralSlotExtractor:\n",
    "    \"\"\"\n",
    "    Extracteur de slots utilisant Mistral-7B-Instruct en local\n",
    "    Optimis√© pour l'extraction d'informations structur√©es\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str = \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        local_model_path: str = \"../models/mistral-7b-instruct\",  # Nouveau param√®tre\n",
    "        device: str = \"auto\",\n",
    "        load_in_8bit: bool = False,\n",
    "        load_in_4bit: bool = True\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialise le mod√®le Mistral\n",
    "        \n",
    "        Args:\n",
    "            model_name: Nom du mod√®le sur HuggingFace\n",
    "            device: Device √† utiliser ('cuda', 'cpu', ou 'auto')\n",
    "            load_in_8bit: Charger en quantification 8-bit (n√©cessite bitsandbytes)\n",
    "            load_in_4bit: Charger en quantification 4-bit (recommand√©, √©conomise de la VRAM)\n",
    "        \"\"\"\n",
    "           \n",
    "        # V√©rifier si le mod√®le existe d√©j√† en local\n",
    "        if os.path.exists(local_model_path):\n",
    "            print(f\"üîÑ Chargement du mod√®le depuis {local_model_path}...\")\n",
    "            model_name = local_model_path\n",
    "        else:\n",
    "            print(f\"üîÑ Chargement du mod√®le {model_name} depuis HuggingFace...\")\n",
    "        \n",
    "        print(torch.cuda.is_available())\n",
    "        self.device = device if device != \"auto\" else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    \n",
    "        \n",
    "        # Configuration de quantification pour √©conomiser la m√©moire\n",
    "        kwargs = {}\n",
    "        if load_in_4bit and self.device == \"cuda\":\n",
    "            kwargs[\"load_in_4bit\"] = True\n",
    "            kwargs[\"device_map\"] = \"auto\"\n",
    "            print(\"   Using 4-bit quantization\")\n",
    "        elif load_in_8bit and self.device == \"cuda\":\n",
    "            kwargs[\"load_in_8bit\"] = True\n",
    "            kwargs[\"device_map\"] = \"auto\"\n",
    "            print(\"   Using 8-bit quantization\")\n",
    "        else:\n",
    "            kwargs[\"torch_dtype\"] = torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "        \n",
    "        # Chargement\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name, **kwargs)\n",
    "        \n",
    "        if not load_in_4bit and not load_in_8bit:\n",
    "            self.model = self.model.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        # Sauvegarder en local si ce n'est pas d√©j√† fait\n",
    "        if not os.path.exists(local_model_path):\n",
    "            print(f\"üíæ Sauvegarde du mod√®le dans {local_model_path}...\")\n",
    "            os.makedirs(local_model_path, exist_ok=True)\n",
    "            self.tokenizer.save_pretrained(local_model_path)\n",
    "            self.model.save_pretrained(local_model_path)\n",
    "            print(\"‚úì Mod√®le sauvegard√©\")\n",
    "        \n",
    "        print(f\"‚úì Mod√®le charg√© sur {self.device}\")\n",
    "        \n",
    "        # D√©finition des templates pour chaque intention\n",
    "        self.templates = {\n",
    "            'export_notation': {\n",
    "                'slots': ['notation_id'],\n",
    "                'description': 'notation_id est le num√©ro/identifiant de la notation √† exporter (nombre uniquement)'\n",
    "            },\n",
    "            'creer_notation': {\n",
    "                'slots': ['nom', 'description'],\n",
    "                'description': 'nom est le nom de la nouvelle notation, description est une description optionnelle'\n",
    "            },\n",
    "            'creer_essai': {\n",
    "                'slots': ['nom', 'type'],\n",
    "                'description': \"nom est le nom du nouvel essai, type est le type d'essai (optionnel)\"\n",
    "            },\n",
    "            'modifier_essai': {\n",
    "                'slots': ['essai_id', 'champ', 'valeur'],\n",
    "                'description': 'essai_id est l\\'identifiant de l\\'essai, champ est le champ √† modifier, valeur est la nouvelle valeur'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def build_prompt(self, text: str, intent: str) -> str:\n",
    "        \"\"\"\n",
    "        Construit le prompt pour Mistral au format Instruct\n",
    "        \"\"\"\n",
    "        template_info = self.templates.get(intent, {})\n",
    "        slots = template_info.get('slots', [])\n",
    "        description = template_info.get('description', '')\n",
    "        \n",
    "        # Construction du JSON de sortie attendu\n",
    "        json_schema = {slot: \"valeur ou null\" for slot in slots}\n",
    "        json_example = json.dumps(json_schema, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Prompt optimis√© pour l'extraction\n",
    "        user_message = f\"\"\"Extrait les informations structur√©es de la phrase suivante.\n",
    "\n",
    "Phrase: \"{text}\"\n",
    "Intention: {intent}\n",
    "\n",
    "Informations √† extraire:\n",
    "{description}\n",
    "\n",
    "R√©ponds UNIQUEMENT avec un objet JSON valide, sans texte avant ou apr√®s.\n",
    "Format attendu:\n",
    "{json_example}\n",
    "\n",
    "Si une information n'est pas pr√©sente dans la phrase, utilise null.\"\"\"\n",
    "\n",
    "        return user_message\n",
    "    \n",
    "    def format_mistral_prompt(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Formate le prompt au format Mistral Instruct\n",
    "        \"\"\"\n",
    "        return f\"<s>[INST] {user_message} [/INST]\"\n",
    "    \n",
    "    def generate(self, prompt: str, max_new_tokens: int = 150, temperature: float = 0.1) -> str:\n",
    "        \"\"\"\n",
    "        G√©n√®re une r√©ponse avec le mod√®le Mistral\n",
    "        \n",
    "        Args:\n",
    "            prompt: Le prompt format√©\n",
    "            max_new_tokens: Nombre maximum de tokens √† g√©n√©rer\n",
    "            temperature: Temp√©rature de g√©n√©ration (plus bas = plus d√©terministe)\n",
    "        \"\"\"\n",
    "        # Tokenisation\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        \n",
    "        # G√©n√©ration\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=temperature > 0,\n",
    "                top_p=0.95,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # D√©codage (enl√®ve le prompt)\n",
    "        generated_text = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        return generated_text.strip()\n",
    "    \n",
    "    def extract_json_from_response(self, response: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Extrait un objet JSON de la r√©ponse (g√®re les cas o√π le mod√®le ajoute du texte)\n",
    "        \"\"\"\n",
    "        # M√©thode 1: Chercher un bloc JSON avec regex\n",
    "        json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
    "        matches = re.findall(json_pattern, response, re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            try:\n",
    "                return json.loads(match)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        # M√©thode 2: Essayer de parser directement\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        \n",
    "        # M√©thode 3: Nettoyer et r√©essayer\n",
    "        cleaned = response.strip()\n",
    "        if cleaned.startswith('```json'):\n",
    "            cleaned = cleaned[7:]\n",
    "        if cleaned.startswith('```'):\n",
    "            cleaned = cleaned[3:]\n",
    "        if cleaned.endswith('```'):\n",
    "            cleaned = cleaned[:-3]\n",
    "        \n",
    "        try:\n",
    "            return json.loads(cleaned.strip())\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    \n",
    "    def extract(self, text: str, intent: str, verbose: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extrait les slots depuis le texte pour l'intention donn√©e\n",
    "        \n",
    "        Args:\n",
    "            text: La phrase utilisateur\n",
    "            intent: L'intention d√©tect√©e\n",
    "            verbose: Affiche les d√©tails de g√©n√©ration\n",
    "        \n",
    "        Returns:\n",
    "            Dictionnaire des slots extraits\n",
    "        \"\"\"\n",
    "        # Construction du prompt\n",
    "        user_message = self.build_prompt(text, intent)\n",
    "        prompt = self.format_mistral_prompt(user_message)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nüìù Prompt envoy√© au mod√®le:\")\n",
    "            print(f\"{user_message}\\n\")\n",
    "        \n",
    "        # G√©n√©ration\n",
    "        response = self.generate(prompt)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ü§ñ R√©ponse brute du mod√®le:\")\n",
    "            print(f\"{response}\\n\")\n",
    "        \n",
    "        # Extraction du JSON\n",
    "        slots = self.extract_json_from_response(response)\n",
    "        \n",
    "        if slots is None:\n",
    "            if verbose:\n",
    "                print(\"‚ö†Ô∏è  √âchec de l'extraction JSON, retour d'un dict vide\")\n",
    "            return {}\n",
    "        \n",
    "        # Nettoyage des valeurs null\n",
    "        slots = {k: v for k, v in slots.items() if v is not None and v != \"null\"}\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"‚úì Slots extraits: {slots}\")\n",
    "        \n",
    "        return slots\n",
    "    \n",
    "    def extract_batch(self, texts_and_intents: list, verbose: bool = False) -> list:\n",
    "        \"\"\"\n",
    "        Extrait les slots pour plusieurs phrases en batch\n",
    "        \n",
    "        Args:\n",
    "            texts_and_intents: Liste de tuples (text, intent)\n",
    "            verbose: Affiche les d√©tails\n",
    "        \n",
    "        Returns:\n",
    "            Liste de dictionnaires de slots\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text, intent in texts_and_intents:\n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(f\"Traitement: '{text}' (intent: {intent})\")\n",
    "                print('='*70)\n",
    "            \n",
    "            slots = self.extract(text, intent, verbose=verbose)\n",
    "            results.append(slots)\n",
    "        \n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb0d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# APPROCHE 4: Syst√®me hybride (Recommand√©)\n",
    "# ============================================================================\n",
    "\n",
    "class HybridSlotExtractor:\n",
    "    \"\"\"\n",
    "    Combine plusieurs approches:\n",
    "    1. Essaie d'abord les r√®gles (rapide, pr√©cis pour cas simples)\n",
    "    2. Si insuffisant, utilise NER ou LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rule_extractor = RuleBasedSlotExtractor()\n",
    "        # self.ner_extractor = NERSlotExtractor()  # Si mod√®le entra√Æn√©\n",
    "        self.llm_extractor = MistralSlotExtractor(device=\"cpu\")\n",
    "    \n",
    "    def extract(self, text: str, intent: str, use_llm: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extrait les slots en utilisant la meilleure approche\n",
    "        \n",
    "        Args:\n",
    "            text: La phrase utilisateur\n",
    "            intent: L'intention d√©tect√©e\n",
    "            use_llm: Si True, utilise le LLM pour les cas complexes\n",
    "        \"\"\"\n",
    "        # Essaie d'abord les r√®gles\n",
    "        slots = self.rule_extractor.extract(text, intent)\n",
    "        \n",
    "        # Si on a trouv√© des slots, c'est bon\n",
    "        if slots:\n",
    "            return {'method': 'rules', 'slots': slots, 'confidence': 'high'}\n",
    "        \n",
    "        # Sinon, utilise le LLM si demand√©\n",
    "        if use_llm:\n",
    "            slots = self.llm_extractor.extract(text, intent)\n",
    "            return {'method': 'llm', 'slots': slots, 'confidence': 'medium'}\n",
    "        \n",
    "        return {'method': 'none', 'slots': {}, 'confidence': 'low'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c9cb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "D√âMONSTRATION D'EXTRACTION DE SLOTS\n",
      "======================================================================\n",
      "\n",
      "üîß APPROCHE 1: R√àGLES ET REGEX\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìù 'export de la notation 345'\n",
      "   Intent: export_notation\n",
      "   Slots: {'notation_id': '345'}\n",
      "\n",
      "üìù 'je veux exporter la notation num√©ro 789'\n",
      "   Intent: export_notation\n",
      "   Slots: {'notation_id': '789'}\n",
      "\n",
      "üìù 'exporter n¬∞ 123'\n",
      "   Intent: export_notation\n",
      "   Slots: {'notation_id': '123'}\n",
      "\n",
      "üìù 'cr√©er une notation analyse des risques'\n",
      "   Intent: creer_notation\n",
      "   Slots: {'notation_nom': 'analyse des risques'}\n",
      "\n",
      "üìù 'nouveau essai de r√©sistance'\n",
      "   Intent: creer_essai\n",
      "   Slots: {'essai_nom': 'de r√©sistance'}\n",
      "\n",
      "\n",
      "ü§ñ APPROCHE 2: NER (Named Entity Recognition)\n",
      "----------------------------------------------------------------------\n",
      "N√©cessite un mod√®le entra√Æn√© sur des donn√©es annot√©es BIO\n",
      "Exemple de donn√©es d'entra√Ænement (7 exemples):\n",
      "\n",
      "  Exemple 1:\n",
      "    Texte: export de la notation 123\n",
      "    Tokens: ['<s>', '‚ñÅexport', '‚ñÅde', '‚ñÅla', '‚ñÅnotation', '‚ñÅ123', '</s>']...\n",
      "    Labels: ['O', 'O', 'O', 'O', 'O', 'B-notation_id', 'O']...\n",
      "\n",
      "  Exemple 2:\n",
      "    Texte: exporter notation 456\n",
      "    Tokens: ['<s>', '‚ñÅexport', 'er', '‚ñÅnotation', '‚ñÅ4', '56', '</s>']...\n",
      "    Labels: ['O', 'O', 'O', 'O', 'B-notation_id', 'I-notation_id', 'O']...\n",
      "\n",
      "\n",
      "üß† APPROCHE 3: LLM (Large Language Model)\n",
      "----------------------------------------------------------------------\n",
      "üîÑ Chargement du mod√®le mistralai/Mistral-7B-Instruct-v0.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [03:07<00:00, 62.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mod√®le charg√© sur cpu\n",
      "\n",
      "üìù 'export de la notation 345'\n",
      "   Intent: export_notation\n",
      "   Slots: {'notation_id': '345'}\n",
      "\n",
      "üìù 'je veux exporter la notation num√©ro 789'\n",
      "   Intent: export_notation\n",
      "   Slots: {'notation_id': '789'}\n",
      "\n",
      "üìù 'exporter n¬∞ 123'\n",
      "   Intent: export_notation\n",
      "   Slots: {'notation_id': '123'}\n",
      "\n",
      "\n",
      "‚ö° APPROCHE 4: SYST√àME HYBRIDE (RECOMMAND√â)\n",
      "----------------------------------------------------------------------\n",
      "üîÑ Chargement du mod√®le mistralai/Mistral-7B-Instruct-v0.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [02:03<00:00, 41.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mod√®le charg√© sur cpu\n",
      "\n",
      "üìù 'export de la notation 345'\n",
      "   Intent: export_notation\n",
      "   M√©thode: rules\n",
      "   Confiance: high\n",
      "   Slots: {'notation_id': '345'}\n",
      "\n",
      "üìù 'je veux exporter la notation num√©ro 789'\n",
      "   Intent: export_notation\n",
      "   M√©thode: rules\n",
      "   Confiance: high\n",
      "   Slots: {'notation_id': '789'}\n",
      "\n",
      "üìù 'exporter n¬∞ 123'\n",
      "   Intent: export_notation\n",
      "   M√©thode: rules\n",
      "   Confiance: high\n",
      "   Slots: {'notation_id': '123'}\n",
      "\n",
      "üìù 'cr√©er une notation analyse des risques'\n",
      "   Intent: creer_notation\n",
      "   M√©thode: rules\n",
      "   Confiance: high\n",
      "   Slots: {'notation_nom': 'analyse des risques'}\n",
      "\n",
      "üìù 'nouveau essai de r√©sistance'\n",
      "   Intent: creer_essai\n",
      "   M√©thode: rules\n",
      "   Confiance: high\n",
      "   Slots: {'essai_nom': 'de r√©sistance'}\n",
      "\n",
      "\n",
      "üí° RECOMMANDATIONS\n",
      "======================================================================\n",
      "\n",
      "1. R√àGLES + REGEX (Recommand√© pour commencer):\n",
      "   ‚úì Simple √† impl√©menter et maintenir\n",
      "   ‚úì Tr√®s rapide (< 1ms)\n",
      "   ‚úì Pr√©cis pour les patterns connus\n",
      "   ‚úì Pas besoin d'entra√Ænement\n",
      "   ‚úó Limit√© aux patterns pr√©d√©finis\n",
      "   \n",
      "2. NER (Pour cas plus complexes):\n",
      "   ‚úì Plus flexible que les r√®gles\n",
      "   ‚úì Peut g√©rer des variations\n",
      "   ‚úì Bonne pr√©cision avec peu de donn√©es (100-200 exemples)\n",
      "   ‚úó N√©cessite annotation des donn√©es\n",
      "   ‚úó Temps d'entra√Ænement\n",
      "   \n",
      "3. LLM (Pour flexibilit√© maximale):\n",
      "   ‚úì Tr√®s flexible, comprend le contexte\n",
      "   ‚úì Pas besoin d'entra√Ænement\n",
      "   ‚úì G√®re les cas complexes\n",
      "   ‚úó Co√ªt API ou ressources GPU\n",
      "   ‚úó Latence plus √©lev√©e (100-1000ms)\n",
      "   ‚úó Moins pr√©dictible\n",
      "   \n",
      "4. HYBRIDE (Meilleur compromis):\n",
      "   ‚úì Combine avantages de chaque approche\n",
      "   ‚úì R√®gles pour cas simples (rapide)\n",
      "   ‚úì LLM pour cas complexes (flexible)\n",
      "   ‚úì Optimise co√ªt/performance\n",
      "   \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# D√âMONSTRATION\n",
    "# ============================================================================\n",
    "\n",
    "def demo():\n",
    "    \"\"\"D√©monstration des diff√©rentes approches\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"D√âMONSTRATION D'EXTRACTION DE SLOTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    test_cases = [\n",
    "        (\"export de la notation 345\", \"export_notation\"),\n",
    "        (\"je veux exporter la notation num√©ro 789\", \"export_notation\"),\n",
    "        (\"exporter n¬∞ 123\", \"export_notation\"),\n",
    "        (\"cr√©er une notation analyse des risques\", \"creer_notation\"),\n",
    "        (\"nouveau essai de r√©sistance\", \"creer_essai\"),\n",
    "    ]\n",
    "    \n",
    "    # Approche 1: R√®gles\n",
    "    print(\"\\nüîß APPROCHE 1: R√àGLES ET REGEX\")\n",
    "    print(\"-\" * 70)\n",
    "    rule_extractor = RuleBasedSlotExtractor()\n",
    "    \n",
    "    for text, intent in test_cases:\n",
    "        slots = rule_extractor.extract(text, intent)\n",
    "        print(f\"\\nüìù '{text}'\")\n",
    "        print(f\"   Intent: {intent}\")\n",
    "        print(f\"   Slots: {slots}\")\n",
    "    \n",
    "    # Approche 2: NER\n",
    "    print(\"\\n\\nü§ñ APPROCHE 2: NER (Named Entity Recognition)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"N√©cessite un mod√®le entra√Æn√© sur des donn√©es annot√©es BIO\")\n",
    "    ner_extractor = NERSlotExtractor()\n",
    "    training_data = ner_extractor.create_training_data()\n",
    "    print(f\"Exemple de donn√©es d'entra√Ænement ({len(training_data)} exemples):\")\n",
    "    for i, example in enumerate(training_data[:2]):\n",
    "        print(f\"\\n  Exemple {i+1}:\")\n",
    "        print(f\"    Texte: {example['text']}\")\n",
    "        print(f\"    Tokens: {example['tokens'][:10]}...\")\n",
    "        print(f\"    Labels: {example['labels'][:10]}...\")\n",
    "    \n",
    "    # Approche 3: LLM\n",
    "    print(\"\\n\\nüß† APPROCHE 3: LLM (Large Language Model)\")\n",
    "    print(\"-\" * 70)\n",
    "    llm_extractor = MistralSlotExtractor()\n",
    "    \n",
    "    for text, intent in test_cases[:3]:\n",
    "        slots = llm_extractor.extract(text, intent)\n",
    "        print(f\"\\nüìù '{text}'\")\n",
    "        print(f\"   Intent: {intent}\")\n",
    "        print(f\"   Slots: {slots}\")\n",
    "    \n",
    "    # Approche 4: Hybride\n",
    "    print(\"\\n\\n‚ö° APPROCHE 4: SYST√àME HYBRIDE (RECOMMAND√â)\")\n",
    "    print(\"-\" * 70)\n",
    "    hybrid_extractor = HybridSlotExtractor()\n",
    "    \n",
    "    for text, intent in test_cases:\n",
    "        result = hybrid_extractor.extract(text, intent)\n",
    "        print(f\"\\nüìù '{text}'\")\n",
    "        print(f\"   Intent: {intent}\")\n",
    "        print(f\"   M√©thode: {result['method']}\")\n",
    "        print(f\"   Confiance: {result['confidence']}\")\n",
    "        print(f\"   Slots: {result['slots']}\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(\"\\n\\nüí° RECOMMANDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\"\"\n",
    "1. R√àGLES + REGEX (Recommand√© pour commencer):\n",
    "   ‚úì Simple √† impl√©menter et maintenir\n",
    "   ‚úì Tr√®s rapide (< 1ms)\n",
    "   ‚úì Pr√©cis pour les patterns connus\n",
    "   ‚úì Pas besoin d'entra√Ænement\n",
    "   ‚úó Limit√© aux patterns pr√©d√©finis\n",
    "   \n",
    "2. NER (Pour cas plus complexes):\n",
    "   ‚úì Plus flexible que les r√®gles\n",
    "   ‚úì Peut g√©rer des variations\n",
    "   ‚úì Bonne pr√©cision avec peu de donn√©es (100-200 exemples)\n",
    "   ‚úó N√©cessite annotation des donn√©es\n",
    "   ‚úó Temps d'entra√Ænement\n",
    "   \n",
    "3. LLM (Pour flexibilit√© maximale):\n",
    "   ‚úì Tr√®s flexible, comprend le contexte\n",
    "   ‚úì Pas besoin d'entra√Ænement\n",
    "   ‚úì G√®re les cas complexes\n",
    "   ‚úó Co√ªt API ou ressources GPU\n",
    "   ‚úó Latence plus √©lev√©e (100-1000ms)\n",
    "   ‚úó Moins pr√©dictible\n",
    "   \n",
    "4. HYBRIDE (Meilleur compromis):\n",
    "   ‚úì Combine avantages de chaque approche\n",
    "   ‚úì R√®gles pour cas simples (rapide)\n",
    "   ‚úì LLM pour cas complexes (flexible)\n",
    "   ‚úì Optimise co√ªt/performance\n",
    "   \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae9838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Chargement du mod√®le depuis ../models/mistral-7b-instruct...\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 54.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mod√®le charg√© sur cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'rules', 'slots': {'notation_id': '415'}, 'confidence': 'high'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_extractor = HybridSlotExtractor()\n",
    "\n",
    "result = hybrid_extractor.extract(\"Je voudrais exporter les r√©sultats de la notation 415\", \"export_notation\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c4b62e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'rules', 'slots': {'notation_id': '567'}, 'confidence': 'high'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = hybrid_extractor.extract(\"Je voudrais exporter la notation 567\", \"export_notation\", use_llm=True)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
