{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fca5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shadow\\anaconda3\\envs\\hermes\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import des librairies\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from torch.optim import AdamW  # AdamW est maintenant dans torch.optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff45421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Données d'expérimentation\n",
    "\n",
    "data = [\n",
    "    # Exporter notation\n",
    "    (\"export de la notation 123\", \"export_notation\"),\n",
    "    (\"exporter notation 456\", \"export_notation\"),\n",
    "    (\"je veux exporter la notation 789\", \"export_notation\"),\n",
    "    (\"export notation numéro 12\", \"export_notation\"),\n",
    "    (\"exporte moi la notation 45\", \"export_notation\"),\n",
    "    (\"j'ai besoin d'exporter la notation 67\", \"export_notation\"),\n",
    "    (\"peux-tu exporter notation 890\", \"export_notation\"),\n",
    "    (\"export de notation 111\", \"export_notation\"),\n",
    "    (\"télécharger notation 222\", \"export_notation\"),\n",
    "    (\"obtenir export notation 333\", \"export_notation\"),\n",
    "    \n",
    "    # Créer notation\n",
    "    (\"je veux créer une notation\", \"creer_notation\"),\n",
    "    (\"créer une notation\", \"creer_notation\"),\n",
    "    (\"créer notation\", \"creer_notation\"),\n",
    "    (\"nouvelle notation\", \"creer_notation\"),\n",
    "    (\"ajouter une notation\", \"creer_notation\"),\n",
    "    (\"faire une nouvelle notation\", \"creer_notation\"),\n",
    "    (\"je souhaite créer une notation\", \"creer_notation\"),\n",
    "    (\"commencer une notation\", \"creer_notation\"),\n",
    "    (\"démarrer nouvelle notation\", \"creer_notation\"),\n",
    "    (\"initier une notation\", \"creer_notation\"),\n",
    "    \n",
    "    # Créer essai\n",
    "    (\"je veux créer un essai\", \"creer_essai\"),\n",
    "    (\"créer un essai\", \"creer_essai\"),\n",
    "    (\"créer essai\", \"creer_essai\"),\n",
    "    (\"nouvel essai\", \"creer_essai\"),\n",
    "    (\"ajouter un essai\", \"creer_essai\"),\n",
    "    (\"faire un nouvel essai\", \"creer_essai\"),\n",
    "    (\"je souhaite créer un essai\", \"creer_essai\"),\n",
    "    (\"commencer un essai\", \"creer_essai\"),\n",
    "    (\"démarrer nouvel essai\", \"creer_essai\"),\n",
    "    (\"initier un essai\", \"creer_essai\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d185ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des labels vers des indices\n",
    "label_to_id = {\n",
    "    \"export_notation\": 0,\n",
    "    \"creer_notation\": 1,\n",
    "    \"creer_essai\": 2\n",
    "}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adf21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset personnalisé\n",
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=64):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4059a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader, model, device):\n",
    "    \"\"\"Évalue le modèle\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68641812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader, model, optimizer, device, epochs=3):\n",
    "    \"\"\"Entraîne le modèle\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e11d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text, model, tokenizer, device):\n",
    "    \"\"\"Prédit l'intention pour une phrase\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        confidence = probs[0][pred].item()\n",
    "    \n",
    "    return id_to_label[pred.item()], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4d554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de: cpu\n",
      "Données d'entraînement: 24\n",
      "Données de test: 6\n",
      "\n",
      "Chargement de CamemBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shadow\\anaconda3\\envs\\hermes\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shadow\\.cache\\huggingface\\hub\\models--camembert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Utilisation de: {device}\")\n",
    "    \n",
    "# Préparation des données\n",
    "texts = [item[0] for item in data]\n",
    "labels = [label_to_id[item[1]] for item in data]\n",
    "    \n",
    "# Split train/test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "    \n",
    "print(f\"Données d'entraînement: {len(train_texts)}\")\n",
    "print(f\"Données de test: {len(test_texts)}\")\n",
    "\n",
    "# Chargement du tokenizer et du modèle\n",
    "print(\"\\nChargement de CamemBERT...\")\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model = CamembertForSequenceClassification.from_pretrained(\n",
    "    'camembert-base',\n",
    "    num_labels=len(label_to_id)\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d87aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des datasets\n",
    "train_dataset = IntentDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = IntentDataset(test_texts, test_labels, tokenizer)\n",
    "    \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08000d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement du modèle...\n",
      "Epoch 1/5, Loss: 1.1020\n",
      "Epoch 2/5, Loss: 1.0898\n",
      "Epoch 3/5, Loss: 1.0709\n",
      "Epoch 4/5, Loss: 1.0612\n",
      "Epoch 5/5, Loss: 1.0467\n"
     ]
    }
   ],
   "source": [
    "# Entraînement\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "print(\"\\nEntraînement du modèle...\")\n",
    "train_model(train_dataloader, model, optimizer, device, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e467143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Évaluation sur le jeu de test...\n",
      "\n",
      "Rapport de classification:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "export_notation       1.00      1.00      1.00         2\n",
      " creer_notation       1.00      1.00      1.00         2\n",
      "    creer_essai       1.00      1.00      1.00         2\n",
      "\n",
      "       accuracy                           1.00         6\n",
      "      macro avg       1.00      1.00      1.00         6\n",
      "   weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation\n",
    "print(\"\\nÉvaluation sur le jeu de test...\")\n",
    "predictions, true_labels = evaluate_model(test_dataloader, model, device)\n",
    "    \n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predictions,\n",
    "    target_names=list(label_to_id.keys())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4a942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Tests sur de nouvelles phrases:\n",
      "==================================================\n",
      "\n",
      "Phrase: 'je voudrais exporter la notation 555'\n",
      "  → Intention: export_notation\n",
      "  → Confiance: 37.17%\n",
      "\n",
      "Phrase: 'créer une nouvelle notation s'il te plaît'\n",
      "  → Intention: creer_notation\n",
      "  → Confiance: 34.41%\n",
      "\n",
      "Phrase: 'faire un essai'\n",
      "  → Intention: creer_essai\n",
      "  → Confiance: 35.62%\n",
      "\n",
      "Phrase: 'export notation 999'\n",
      "  → Intention: export_notation\n",
      "  → Confiance: 37.62%\n",
      "\n",
      "Phrase: 'ajouter essai'\n",
      "  → Intention: creer_essai\n",
      "  → Confiance: 34.43%\n",
      "\n",
      "Phrase: 'Créer une notation depuis l'essai 43'\n",
      "  → Intention: export_notation\n",
      "  → Confiance: 34.26%\n"
     ]
    }
   ],
   "source": [
    "# Test sur de nouvelles phrases\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Tests sur de nouvelles phrases:\")\n",
    "print(\"=\"*50)\n",
    "    \n",
    "test_phrases = [\n",
    "    \"je voudrais exporter la notation 555\",\n",
    "    \"créer une nouvelle notation s'il te plaît\",\n",
    "    \"faire un essai\",\n",
    "    \"export notation 999\",\n",
    "    \"ajouter essai\",\n",
    "    \"Créer une notation depuis l'essai 43\"\n",
    "]\n",
    "    \n",
    "for phrase in test_phrases:\n",
    "    intent, confidence = predict_intent(phrase, model, tokenizer, device)\n",
    "    print(f\"\\nPhrase: '{phrase}'\")\n",
    "    print(f\"  → Intention: {intent}\")\n",
    "    print(f\"  → Confiance: {confidence:.2%}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64364924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde du modèle...\n",
      "Modèle sauvegardé\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle\n",
    "print(\"\\nSauvegarde du modèle...\")\n",
    "model.save_pretrained('../models/hermes-v1')\n",
    "tokenizer.save_pretrained('../models/hermes-v1')\n",
    "print(\"Modèle sauvegardé\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hermes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
