{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fca5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgerard/python/hermes/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import des librairies\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from torch.optim import AdamW  # AdamW est maintenant dans torch.optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff45421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Données d'expérimentation\n",
    "\n",
    "data = [\n",
    "    # Exporter notation\n",
    "    (\"export de la notation 123\", \"export_notation\"),\n",
    "    (\"exporter notation 456\", \"export_notation\"),\n",
    "    (\"je veux exporter la notation 789\", \"export_notation\"),\n",
    "    (\"export notation numéro 12\", \"export_notation\"),\n",
    "    (\"exporte moi la notation 45\", \"export_notation\"),\n",
    "    (\"j'ai besoin d'exporter la notation 67\", \"export_notation\"),\n",
    "    (\"peux-tu exporter notation 890\", \"export_notation\"),\n",
    "    (\"export de notation 111\", \"export_notation\"),\n",
    "    (\"télécharger notation 222\", \"export_notation\"),\n",
    "    (\"obtenir export notation 333\", \"export_notation\"),\n",
    "    \n",
    "    # Créer notation\n",
    "    (\"je veux créer une notation\", \"creer_notation\"),\n",
    "    (\"créer une notation\", \"creer_notation\"),\n",
    "    (\"créer notation\", \"creer_notation\"),\n",
    "    (\"nouvelle notation\", \"creer_notation\"),\n",
    "    (\"ajouter une notation\", \"creer_notation\"),\n",
    "    (\"faire une nouvelle notation\", \"creer_notation\"),\n",
    "    (\"je souhaite créer une notation\", \"creer_notation\"),\n",
    "    (\"commencer une notation\", \"creer_notation\"),\n",
    "    (\"démarrer nouvelle notation\", \"creer_notation\"),\n",
    "    (\"initier une notation\", \"creer_notation\"),\n",
    "    \n",
    "    # Créer essai\n",
    "    (\"je veux créer un essai\", \"creer_essai\"),\n",
    "    (\"créer un essai\", \"creer_essai\"),\n",
    "    (\"créer essai\", \"creer_essai\"),\n",
    "    (\"nouvel essai\", \"creer_essai\"),\n",
    "    (\"ajouter un essai\", \"creer_essai\"),\n",
    "    (\"faire un nouvel essai\", \"creer_essai\"),\n",
    "    (\"je souhaite créer un essai\", \"creer_essai\"),\n",
    "    (\"commencer un essai\", \"creer_essai\"),\n",
    "    (\"démarrer nouvel essai\", \"creer_essai\"),\n",
    "    (\"initier un essai\", \"creer_essai\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d185ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des labels vers des indices\n",
    "label_to_id = {\n",
    "    \"export_notation\": 0,\n",
    "    \"creer_notation\": 1,\n",
    "    \"creer_essai\": 2\n",
    "}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adf21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset personnalisé\n",
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=64):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4059a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader, model, device):\n",
    "    \"\"\"Évalue le modèle\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68641812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader, model, optimizer, device, epochs=3):\n",
    "    \"\"\"Entraîne le modèle\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e11d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text, model, tokenizer, device):\n",
    "    \"\"\"Prédit l'intention pour une phrase\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=64,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        confidence = probs[0][pred].item()\n",
    "    \n",
    "    return id_to_label[pred.item()], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4d554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de: cpu\n",
      "Type du premier label_id: <class 'int'>\n",
      "Exemple de label_ids: [0, 0, 0, 0, 0]\n",
      "Données d'entraînement: 24\n",
      "Données de test: 6\n",
      "\n",
      "Chargement de CamemBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Utilisation de: {device}\")\n",
    "    \n",
    "# Préparation des données\n",
    "texts = [item[0] for item in data]\n",
    "labels = [label_to_id[item[1]] for item in data]\n",
    "\n",
    "print(f\"Type du premier label_id: {type(labels[0])}\")\n",
    "print(f\"Exemple de label_ids: {labels[:5]}\")\n",
    "    \n",
    "# Split train/test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "    \n",
    "print(f\"Données d'entraînement: {len(train_texts)}\")\n",
    "print(f\"Données de test: {len(test_texts)}\")\n",
    "\n",
    "# Chargement du tokenizer et du modèle\n",
    "print(\"\\nChargement de CamemBERT...\")\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model = CamembertForSequenceClassification.from_pretrained(\n",
    "    'camembert-base',\n",
    "    num_labels=len(label_to_id)\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d87aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des datasets\n",
    "train_dataset = IntentDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = IntentDataset(test_texts, test_labels, tokenizer)\n",
    "    \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08000d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement du modèle...\n",
      "Epoch 1/5, Loss: 1.1041\n",
      "Epoch 2/5, Loss: 1.0892\n",
      "Epoch 3/5, Loss: 1.0864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m optimizer = AdamW(model.parameters(), lr=\u001b[32m2e-5\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEntraînement du modèle...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(train_dataloader, model, optimizer, device, epochs)\u001b[39m\n\u001b[32m     20\u001b[39m     loss = outputs.loss\n\u001b[32m     21\u001b[39m     total_loss += loss.item()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     optimizer.step()\n\u001b[32m     26\u001b[39m avg_loss = total_loss / \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/hermes/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/hermes/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python/hermes/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Entraînement\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "print(\"\\nEntraînement du modèle...\")\n",
    "train_model(train_dataloader, model, optimizer, device, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e467143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Évaluation sur le jeu de test...\n",
      "\n",
      "Rapport de classification:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "export_notation       1.00      1.00      1.00         2\n",
      " creer_notation       1.00      1.00      1.00         2\n",
      "    creer_essai       1.00      1.00      1.00         2\n",
      "\n",
      "       accuracy                           1.00         6\n",
      "      macro avg       1.00      1.00      1.00         6\n",
      "   weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluation\n",
    "print(\"\\nÉvaluation sur le jeu de test...\")\n",
    "predictions, true_labels = evaluate_model(test_dataloader, model, device)\n",
    "    \n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predictions,\n",
    "    target_names=list(label_to_id.keys())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4a942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Tests sur de nouvelles phrases:\n",
      "==================================================\n",
      "\n",
      "Phrase: 'je voudrais exporter la notation 555'\n",
      "  → Intention: export_notation\n",
      "  → Confiance: 37.17%\n",
      "\n",
      "Phrase: 'créer une nouvelle notation s'il te plaît'\n",
      "  → Intention: creer_notation\n",
      "  → Confiance: 34.41%\n",
      "\n",
      "Phrase: 'faire un essai'\n",
      "  → Intention: creer_essai\n",
      "  → Confiance: 35.62%\n",
      "\n",
      "Phrase: 'export notation 999'\n",
      "  → Intention: export_notation\n",
      "  → Confiance: 37.62%\n",
      "\n",
      "Phrase: 'ajouter essai'\n",
      "  → Intention: creer_essai\n",
      "  → Confiance: 34.43%\n",
      "\n",
      "Phrase: 'Créer une notation depuis l'essai 43'\n",
      "  → Intention: export_notation\n",
      "  → Confiance: 34.26%\n"
     ]
    }
   ],
   "source": [
    "# Test sur de nouvelles phrases\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Tests sur de nouvelles phrases:\")\n",
    "print(\"=\"*50)\n",
    "    \n",
    "test_phrases = [\n",
    "    \"je voudrais exporter la notation 555\",\n",
    "    \"créer une nouvelle notation s'il te plaît\",\n",
    "    \"faire un essai\",\n",
    "    \"export notation 999\",\n",
    "    \"ajouter essai\",\n",
    "    \"Créer une notation depuis l'essai 43\"\n",
    "]\n",
    "    \n",
    "for phrase in test_phrases:\n",
    "    intent, confidence = predict_intent(phrase, model, tokenizer, device)\n",
    "    print(f\"\\nPhrase: '{phrase}'\")\n",
    "    print(f\"  → Intention: {intent}\")\n",
    "    print(f\"  → Confiance: {confidence:.2%}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64364924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde du modèle...\n",
      "Modèle sauvegardé\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle\n",
    "print(\"\\nSauvegarde du modèle...\")\n",
    "model.save_pretrained('../models/hermes-v1')\n",
    "tokenizer.save_pretrained('../models/hermes-v1')\n",
    "print(\"Modèle sauvegardé\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
